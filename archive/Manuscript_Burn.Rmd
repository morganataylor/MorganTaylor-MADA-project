---
title: "Evaluating Machine Learning Methodologies for Predicting Thermal Burn Patient Outcomes"
subtitle: ""
author: Morgan Taylor
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: article
output:
  bookdown::word_document2: 
    toc: false
    number_sections: true
  bookdown::html_document2: 
    toc: false
bibliography: ../references.bib
csl: ../apa.csl
---

# Summary/Abstract
_Write a summary of your project._


# Introduction 

## General Background Information
_Provide enough background on your topic that others can understand the why and how of your analysis_ 
Detonation of a nuclear device over an urban area would generate an unprecedented volume of patients, with injuries resulting from the blast itself, from the thermal energy and fires, and from the radiation emitted from the device. Of all of the injury etiologies, thermal burns may be the least understood, and treatment of such injuries has the greatest resource constraints. A single patient with an extensive burn injury requires a greater commitment of supplies, personnel, and time to achieve optimal outcomes [Saffle 2005]. In particular, thermal burn patients lose heat, plasma, and fluids that, if left uncorrected, can cause hypothermia, hypovolemic shock, and renal insufficiency [Evans 1952]. Moreover, severely burned patients are particularly susceptible to infection [Church 2006], as skin is the primary line of defense in the immune response [Goldman & Schafer, 2011]. The volume of resources required to treat burn patients can be exemplified by treatment cost. Total charges average \$268,435 for surviving patients and \$354,560 for non-surviving patients [NBR 2019 report]. For comparison, the average cost per stay across all healthcare etiologies is $9,700 [Pftuntner et al. 2013]. The accumulation of these factors on a individual patient level suggests the burn care community is poorly positioned to transition to mass casualty care.

To further complicate matters, the broader systemic infrastructure for thermal burn patients is severely limited [Kearns 2020]. Specialized burn centers are designed to care for patients with burns as well as other skin and soft tissue injuries and disorders [NBR Data Dictionary]. Highly specialized teams comprised of burn surgeon(s), nurses, anesthesiologist(s), respiratory therapists, occupational therapists, physical therapists, dietitians, and psychosocial experts staff these burn centers, but there is a severe shortage of trained personnel to supplement these locations [Al-Mousawi et al 2010]. Across the entire United States (US), there are 133 burn centers, only 72 of which are verified by the American Burn Association (ABA). Similarly, there are approximately 300 burn surgeons whose teams cover approximately 2,000 specialty burn beds [Kearns 2020]. Moreover, the sparse nature of these burn centers dictate there are several locations in the US that are hundreds of miles from the closest facility [DHS Burn source]. Kearns et al. [2020] writes, "nationally, the burn care community could manage approximately 2,000 patients if time permits (up to 120 hours), and transportation resources exist to treat and redistribute the patients to centers across the nation." The two assumptions listed are unlikely to be met in a real-world scenario, thus emphasizing the limited capability of the burn healthcare infrastructure to withstand a catastrophic event, such as a nuclear device detonation.

In such circumstances, it is imperative to transition to population patient care by employing triage practices. Coming from the french word "trier," which means "to sort," a healthcare provider triages potential patients by using an established system or plan to determine a treatment priority for each patient [Iserson 2006]. Historically, triage systems are tailored to trauma etiologies and the most commonly used ones are not evidenced-based [Jenkins et al 2008]. The existing triage system for burn patients sorts patients to healthcare destination (outpatient or non-burn center hospital, burn center, and expectant care) based on age and total percent body surface area burned (%TBSA). These criteria are leveraged from prediction scores, such as the Modified Baux Score or the Abbreviated Burn Severity Index (ABSI), which are developed from logistic regressions with patient mortality as the outcome of interest [Halgas et al., 2018]. However, other healthcare disciplines have increasingly transitioned to ML models, which are automatically generated and continually improved, potentially increasing predictive accuracy [Rojas et al., 2018; Taylor et al., 2016]. Preliminary research suggests ML models using artificial neural network (ANN) models can predict burn patient mortality more accurately than commonly used prediction scores [Liu & Salinas, 2015], but there is evidence to suggest random forest models may be more advantageous in emergent applications [Taylor et al., 2016]. The purpose of this study is to examine the accuracy and applicability of ML methods in assessing thermal burn patient mortality and length of stay in burn centers.

## Description of data and data source
_Describe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section._
The ABA created the National Burn Repository (NBR), which is a near-comprehensive record of patients treated at 101 participating burn centers in the US from the years 2009 to 2018. The data set contains 221,519 patient entries, 3,712 of which are reported from international facilities. The data is most frequently collected using the ABA Burn Care Quality Platform and other similar software [NBR Data Dictionary]. Key variables captured in this repository include: distance from patient residence to burn center (based on zip code), age, race, ethnicity, sex, patient occupation, marital status, living situation, injury date, if injury was work related, location of injury, alcohol/drug use, circumstances of injury, ICD-9 / ICD-10 E-code, injury severity, initial clinical presentation, burn center admission information, date of procedure, procedures completed, total length of stay, total ICU length of stay, total ventilator stay, hospital discharge disposition, care directives, and patient financial data.

## Questions/Hypotheses to be addressed
_State the research questions you plan to answer with this analysis._
The long-term goal of this analysis is to better prepare healthcare providers and emergency managers for catastrophic disasters with a significant proportion of burn patients, as would be the case in a nuclear detonation. The primary objective of this analysis is to identify a more sophisticated, machine-learning based model that more accurately predicts burn patient length of stay in hospitals and mortality. Particularly, this study has the following specific objectives:
1.	Create two RF models that respectively predict thermal burn patient length of stay in hospitals and mortality under normal care circumstances
2.	Create two ANN models that respectively predict thermal burn patient length of stay and mortality under normal care circumstances
3.	Compare the accuracy of the ML models with pre-existing, logistic regression-based prediction models

Following identification of a more appropraite outcome prediction model, future studies will apply resource limitations to the model to identify significant predicors of patient mortality and length of stay under catastrophic circumstances.

# Methods and Results

_In most research papers, results and methods are separate. You can combine them here if you find it easier. You are also welcome to structure things such that those are separate sections._


## Data aquisition
_As applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next._
Access to the ABA NBR was achieved via application to the ABA Quality and Burn Registry Committee. Due to Health Insurance Portability and Accountability Act (HIPAA) regulations, the data cannot be provided for the purposes of reproducibility.

## Data import and cleaning
_Write code that reads in the file and cleans it so it's ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along._
The initial 

Inclusion and exclusion criteria were applied based on the guidance from the ABA NBR Report [2019]. Records were excluded if "Admit Type" or "Admit Status" were readmission, admission for reconstruction/rehabilitation, outpatient encounter, same patient, scheduled/elective admission, or acute admission, not burn-related.


## Exploratory analysis

_Use a combination of text/tables/figures to explore and describe your data. You should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. FIgures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data._

_Continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables. Plots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones._

_To get some further insight into your data, if reasonable you could compute simple statistics (e.g. t-tests, simple regression model with 1 predictor, etc.) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p<0.05 means statistical significance" interpretation is not valid._

Table \@ref(tab:summarytable) shows a table summarizing the data.


```{r summarytable,  echo=FALSE}
resulttable=readRDS("../../results/summarytable.rds")
knitr::kable(resulttable, caption = 'Data summary table.')
```


Figure \@ref(fig:resultfigure) shows a scatterplot figure produced by one of the R scripts.

```{r resultfigure,  fig.cap='Analysis figure.', echo=FALSE}
knitr::include_graphics("../../results/resultfigure.png")
```


## Full analysis

_Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here._

Example table \@ref(tab:resulttable) shows a table summarizing a linear model fit.

```{r resulttable,  echo=FALSE}
resulttable=readRDS("../../results/resulttable.rds")
knitr::kable(resulttable, caption = 'Linear model fit table.')
```


# Discussion

## Summary and Interpretation
_Summarize what you did, what you found and what it means._

## Strengths and Limitations
_Discuss what you perceive as strengths and limitations of your analysis._

## Conclusions
_What are the main take-home messages?_

_Include citations in your Rmd file using bibtex, the list of references will automatically be placed at the end_

This paper [@Leek2015a] discusses types of analyses. 

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal [are available](https://www.zotero.org/styles). You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word `references.bib` but giving it a more descriptive name is probably better.


# References



