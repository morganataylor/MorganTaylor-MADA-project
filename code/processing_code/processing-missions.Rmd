---
title: "Data Processing: Mission Assignments"
output: 
  html_document:
    theme: flatly
    toc: FALSE
---
<br>

---

## Introduction
This markdown imports the raw data and performs some cleaning as well as feature engineering. The raw data comes from [the OpenFEMA Dataset website](https://www.fema.gov/openfema-data-page/mission-assignments-v1).

<br>

Overall, processing this dataset involves the following elements:

* Raw data summarization and overview
* Removal of irrelevant variables
* Summarization of mission costs for each state and disaster declaration
* Feature engineering to create cost share proportions
* Saving the processed dataset as an .rds

<br>

To keep track of processing changes, each iteration of processed data will be named `missions_#`. The final processed dataset will be `missions_processed`.

<br>

Ultimately, this processed dataset will be joined to the Disaster Declaration Summaries processed dataset for the analysis.

---

## Required Packages
The following R packages are required for this script:

* here: for path setting
* tidyverse: for all packages in the Tidyverse (ggplot2, dyplr, tidyr, readr, purr, tibble, stringr, forcats)
* skimr: for data summarization
```{r libraries, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load required packages
library(here) #to set paths
library(tidyverse) #for data processing
library(skimr) #for data summarization
```

---

## Load Raw Data
Load the raw data downloaded from provided hyperlink.
```{r load data}
#path to data
#note the use of the here() package and not absolute paths
data_location_ma <- here::here("data", "raw_data", "MissionAssignments.csv")

#load data
missions_raw <- utils::read.csv(data_location_ma, na.strings = c("", "NA"))
```

---

## Raw Data Overview
Examine the summary and structure of the raw data.
```{r raw data overview}
#summary using base R
summary(missions_raw)

#summary and structure using the skimr package
skimr::skim(missions_raw)
```
There are 22 variables in the raw dataset and 21,472 observations. However, there are multiple observations for each disaster declaration and state, as they are listed by each request for assistance or amendment for funding. Time to clean!

---

## Data Cleaning and Wrangling
For the purposes of this project, we only need detail at the disaster declaration number and state level. So we will need to summarize, but first let's remove the variables that are too granular for this analysis. 
```{r variable list}
#print list of variables
colnames(missions_raw)
```

---

Before we get rid of any variables, we need to confirm the date range of this dataset to be able to filter the `DisasterDeclarationsSummaries.csv` dataset.
```{r date range}
#first need to hide na values of `dateRquested` variable
dates <- na.omit(missions_raw$dateRequested)

#first date of requested assistance
min(dates)

#last date of requested assistance
max(dates)
```
So, we know this dataset ranges from February 2, 2012 to November 10, 2021.

---

Now we can remove variables. We only need to keep the following:

* stateorTribe
* disasterNumber
* agency
* stateCostSharePct
* federalCostSharePct
* requestedAmount
* obligationAmount

```{r}
#select target variables
missions_1 <- missions_raw %>%
                dplyr::select(stateorTribe, 
                              disasterNumber, 
                              agency,
                              stateCostSharePct,
                              federalCostSharePct,
                              requestedAmount, 
                              obligationAmount)
```
We now have a dataset with 7 variables and 21,472 variables

---

Before we can sum the rows, we need to address the missing values for the `stateorTribe` variable. Based on the structure of the data, we can use the `fill` function from `tidyr` to write the value based on the previous row.
```{r state name fill}
#fill in missing values for state or tribe
missions_2 <- missions_1 %>%
                tidyr::fill(stateorTribe)
```

---

Now, we can sum the rows to determine the total cost by disaster declaration number, state, and agency that provided the assistance.
```{r row sums}
#sum rows
missions_3 <- missions_2 %>%
                dplyr::group_by(disasterNumber, stateorTribe, agency) %>%
                dplyr::summarize(StateCSProp = sum(stateCostSharePct),
                                 FEMACSProp = sum(federalCostSharePct),
                                 RequestedAmt = sum(requestedAmount),
                                 ObligatedAmt = sum(obligationAmount))
```

---

The next step is to determine the requested and obligated cost share for state governments and FEMA. We will do this first by calculating the cost share percentages for state government and FEMA by agency and disaster declaration, and then we will apply the percentages to the requested and obligated funding amounts.
```{r cost share}
#create variable for state government and FEMA cost share percentages
missions_4 <- missions_3 %>%
                dplyr::mutate(StateCSPct = StateCSProp / (FEMACSProp + StateCSProp),
                              FEMACSPct = FEMACSProp / (FEMACSProp + StateCSProp)) %>%
                subset(select = -c(StateCSProp, FEMACSProp))

#apply cost share percentages to requested and obligated funding
#also create a variable that represents the total percent for total funding requested and/or obligated (e.g. 1)
missions_5 <- missions_4 %>%
                dplyr::mutate(StateReqAmt = RequestedAmt * StateCSPct,
                              FEMAReqAmt = RequestedAmt * FEMACSPct,
                              StateOblAmt = ObligatedAmt * StateCSPct,
                              FEMAOblAmt = ObligatedAmt * FEMACSPct,
                              TotalCSPct = StateCSPct + FEMACSPct)
```

---

Instead of trying to use agencies as a categorical variable, let's convert it to total number of agencies involved in the response. Then we can calculate the sum of the FEMA funding for each disaster number and each state
```{r long format}
#find count of distinct agencies for each disasterNumber and state
missions_6 <- missions_5 %>%
                dplyr::group_by(disasterNumber, stateorTribe) %>%
                dplyr::mutate(TotalAgencies = n_distinct(agency)) %>%
                subset(select = -c(agency))

#convert NaN to na for variables we're keeping
missions_6$FEMACSPct[is.nan(missions_6$FEMACSPct)] <- NA
missions_6$FEMAOblAmt[is.nan(missions_6$FEMAOblAmt)] <- NA
missions_6$FEMAReqAmt[is.nan(missions_6$FEMAReqAmt)] <- NA

#find sum of FEMA funds
missions_7 <- missions_6 %>%
                dplyr::group_by(disasterNumber, stateorTribe, TotalAgencies) %>%
                dplyr::summarize(ReqAmt = sum(FEMAReqAmt, na.rm = TRUE),
                                 OblAmt = sum(FEMAOblAmt, na.rm = TRUE),
                                 FEMACSAvg = mean(FEMACSPct, na.rm = TRUE))

#the NaN values in FEMACSAvg are when FEMA has no cost share (e.g. 0/0), so it can be replaced with 0
missions_7$FEMACSAvg[is.nan(missions_7$FEMACSAvg)] <- 0
```

---

The last step is to make the formatting of state names consistent.
```{r state names}
unique(missions_7$stateorTribe)

#there's probably a more efficient way to do this, but fix all of the non-two letter abbreviations
missions_7$stateorTribe[missions_7$stateorTribe == "Virgin Islands"] <- "VI"
missions_7$stateorTribe[missions_7$stateorTribe == "Seminole Tribe of Florida"] <- "FL"
missions_7$stateorTribe[missions_7$stateorTribe == "Ponca Tribe of Nebraska"] <- "NE"
missions_7$stateorTribe[missions_7$stateorTribe == "MUSCOGEE (CREEK) NATION"] <- "OK"
missions_7$stateorTribe[missions_7$stateorTribe == "Standing Rock Sioux Tribe"] <- "ND"
missions_7$stateorTribe[missions_7$stateorTribe == "Santa Clara Pueblo"] <- "NM"
missions_7$stateorTribe[missions_7$stateorTribe == "Pueblo of Acoma"] <- "NM"
missions_7$stateorTribe[missions_7$stateorTribe == "District of Columbia (DC)"] <- "DC"
missions_7$stateorTribe[missions_7$stateorTribe == "Puerto Rico"] <- "PR"
missions_7$stateorTribe[missions_7$stateorTribe == "American Samoa"] <- "AS"
missions_7$stateorTribe[missions_7$stateorTribe == "Northern Mariana Islands"] <- "MP"
missions_7$stateorTribe[missions_7$stateorTribe == "Choctaw Nation"] <- "OK"
missions_7$stateorTribe[missions_7$stateorTribe == "POTAWATOMI NATION"] <- "OK"
missions_7$stateorTribe[missions_7$stateorTribe == "Oglala Sioux Tribe of the Pine Ridge Reservation"] <- "SD"
```


---

## Processed Data Overview
We have our processed dataset! Let's take a look at the overview to see how it changed.
```{r processed data overview}
#create a mirror set for documentation purposes
missions_processed <- missions_7

#summary using base R
summary(missions_processed)
```

---

## Save Processed Data

Let's save it into the `processed_data` folder.
```{r save processed data}

#location to save processed file
missions_data_location <- here::here("data","processed_data","missionsprocessed.rds")

#save as an RDS
saveRDS(missions_processed, file = missions_data_location)
```